{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Statistics Cross-linguistic: \n",
    "\n",
    "#### Lexical diversity analysis - random sample \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, \"data_proc\")\n",
    "import analytic_proc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_dat_inc = pd.read_csv(\"../data/rand_dat_inc_master.csv\",index_col=0,low_memory=False)\n",
    "rand_dat_inc=rand_dat_inc[rand_dat_inc[\"language\"]!=\"ara\"]\n",
    "rand_dat_inc=rand_dat_inc[(rand_dat_inc[\"target_child_age\"]>=5) & (rand_dat_inc[\"target_child_age\"]<=30)]\n",
    "\n",
    "rand_dat_inc_cg = rand_dat_inc[rand_dat_inc[\"caregiver\"]==\"caregiver\"]\n",
    "\n",
    "rand_dat_inc_cg[\"contingent\"] = np.where(rand_dat_inc_cg[\"contingent\"]==1, \"contingent\", \"non-contingent\")\n",
    "\n",
    "rand_dat_inc_cg = rand_dat_inc_cg[rand_dat_inc_cg[\"gloss\"].notna()]\n",
    "rand_dat_inc_cg = rand_dat_inc_cg[rand_dat_inc_cg[\"gloss\"]!=\"xxx\"]\n",
    "rand_dat_inc_cg = rand_dat_inc_cg[rand_dat_inc_cg[\"gloss\"]!=\"yyy\"]\n",
    "rand_dat_inc_cg = rand_dat_inc_cg[rand_dat_inc_cg[\"gloss\"]!=\"www\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would call the following if we could run lexical diversity analysis globally:\n",
    "\n",
    "```python\n",
    "analytic_proc.create_result(rand_dat_inc_cg)\n",
    "```\n",
    "\n",
    "However, we want to have seperate dictionaries for contingent and non-contingent words so we can compare them to one another.\n",
    "\n",
    "The function will allow us to have a different dictionary for each transcript.\n",
    "\n",
    "Finally, to compare, we can run mixed effects to understand whether contingent and non-contingent utterances differ in their lexical diversity, controlling for number of transcripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### Seperate contingent and non-contingent utterances into individual dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_dat_inc_cg_cc = rand_dat_inc_cg[rand_dat_inc_cg[\"contingent\"]==\"contingent\"].reset_index(drop=True)\n",
    "rand_dat_inc_cg_nc = rand_dat_inc_cg[rand_dat_inc_cg[\"contingent\"]==\"non-contingent\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### Loop through each unique transcript to compute the lexical diversity counts across languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# analytic_proc.create_result(rand_dat_inc_cg_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the \"to_csv\" line at the end of analytic_proc.py first\n",
    "\n",
    "# analytic_proc.create_result(rand_dat_inc_cg_nc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### Lexical Diversity plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_dat_inc_cg_cc = pd.read_csv(\"../data/rand_dat_inc_master_cc_lexdiv.csv\",index_col=0,low_memory=False)\n",
    "rand_dat_inc_cg_nc = pd.read_csv(\"../data/rand_dat_inc_master_nc_lexdiv.csv\",index_col=0,low_memory=False)\n",
    "\n",
    "# combine dataframes into one\n",
    "\n",
    "rand_dat_inc_cg = pd.concat([rand_dat_inc_cg_cc,rand_dat_inc_cg_nc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | stat   |      age |\n",
      "|---:|:-------|---------:|\n",
      "|  0 | min    |  5.98575 |\n",
      "|  1 | max    | 29.9862  |\n",
      "|  2 | mean   | 18.6737  |\n",
      "|  3 | stdev  |  6.83431 |\n"
     ]
    }
   ],
   "source": [
    "ar = [['min', rand_dat_inc_cg[\"target_child_age\"].min()],\n",
    "      ['max', rand_dat_inc_cg[\"target_child_age\"].max()],\n",
    "      ['mean', rand_dat_inc_cg[\"target_child_age\"].mean()],\n",
    "      ['stdev', rand_dat_inc_cg[\"target_child_age\"].std()]]\n",
    "\n",
    "age_range = pd.DataFrame(ar, columns = ['stat', 'age'])\n",
    "\n",
    "print(age_range.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_lex_stats = (rand_dat_inc_cg.groupby([\"Language_name\",\"target_child_id\",\"transcript_id\",\"contingent\"])\n",
    "                                  .uniquenss\n",
    "                                  .agg([\"sum\"])\n",
    "                                  .reset_index())\n",
    "rand_lex_sumstats =  rand_lex_stats.rename({'sum': 'sums'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rand_lex_sumstats[\"Language_name\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1690"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rand_lex_sumstats[\"transcript_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_lex_sumstats.to_csv(\"../data/rand_lex_sumstats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i rand_lex_sumstats\n",
    "\n",
    "library('ggplot2')\n",
    "library('repr')\n",
    "options(repr.plot.width=6, repr.plot.height=12)\n",
    "\n",
    "xlabs <- c(\"C\", \"NC\")\n",
    "\n",
    "# ara_label <- data.frame(means=c(0),contingent = c(1.5),language=\"ara\") # no adult speech transcribed\n",
    "deu_label <- data.frame(sums=c(240),contingent = c(1.5),Language_name=\"German\")\n",
    "eng_label <- data.frame(sums=c(240),contingent = c(1.5),Language_name=\"English\")\n",
    "est_label <- data.frame(sums=c(240),contingent = c(1.5),Language_name=\"Estonian\")\n",
    "fas_label <- data.frame(sums=c(240),contingent = c(1.5),Language_name=\"Persian\")\n",
    "fra_label <- data.frame(sums=c(240),contingent = c(1.5),Language_name=\"French\")\n",
    "hrv_label <- data.frame(sums=c(240),contingent = c(1.5),Language_name=\"Croatian\")\n",
    "jpn_label <- data.frame(sums=c(240),contingent = c(1.5),Language_name=\"Japanese\")\n",
    "kor_label <- data.frame(sums=c(240),contingent = c(1.5),Language_name=\"Korean\")\n",
    "# nor_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"Norwegian\")\n",
    "nor_ns_label <- data.frame(sums=c(247),contingent = c(1.5),Language_name=\"Norwegian\")\n",
    "pol_ns_label <- data.frame(sums=c(247),contingent = c(1.5),Language_name=\"Polish\")\n",
    "por_label <- data.frame(sums=c(240),contingent = c(1.5),Language_name=\"Portuguese\")\n",
    "spa_ns_label <- data.frame(sums=c(247),contingent = c(1.5),Language_name=\"Spanish\")\n",
    "swe_label <- data.frame(sums=c(247),contingent = c(1.5),Language_name=\"Swedish\")\n",
    "zho_label <- data.frame(sums=c(240),contingent = c(1.5),Language_name=\"Mandarin\")\n",
    "# zho_ns_label <- data.frame(means=c(6),contingent = c(1.5),Language_name=\"Mandarin\")\n",
    "\n",
    "\n",
    "p <- ggplot(rand_lex_sumstats, aes(x = contingent, y = sums, color = Language_name)) +\n",
    "     stat_summary(fun.y=mean, geom=\"point\", shape=19, size=1.75) + \n",
    "     stat_summary(fun.data = mean_se, geom = \"errorbar\", size=1.25, width = .5) +\n",
    "     facet_wrap(. ~ Language_name,ncol = 7) + \n",
    "     geom_text(data = deu_label,label = \"***\",size=8,color=\"black\") + \n",
    "     geom_text(data = eng_label,label = \"***\",size=8,color=\"black\") +  \n",
    "     geom_text(data = est_label,label = \"**\",size=8,color=\"black\") +  \n",
    "#      geom_text(data = fas_ns_label,label = \"*\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "     geom_text(data = fas_label,label = \"*\",size=8, color=\"black\") +\n",
    "     geom_text(data = fra_label,label = \"***\",size=8,color=\"black\") +  \n",
    "     geom_text(data = hrv_label,label = \"***\",size=8,color=\"black\") + \n",
    "     geom_text(data = jpn_label,label = \"***\",size=8,color=\"black\") + \n",
    "     geom_text(data = kor_label,label = \"***\",size=8,color=\"black\") +  \n",
    "     geom_text(data = nor_ns_label,label = \"ns\",size=4,color=\"black\",fontface = \"italic\") +  \n",
    "#      geom_text(data = pol_ns_label,label = \"ns\", size=4,color=\"black\",fontface = \"italic\") +  \n",
    "     geom_text(data = por_label,label = \"**\",size=8,color=\"black\") +  \n",
    "     geom_text(data = spa_ns_label,label = \"ns\",size=4,color=\"black\",fontface = \"italic\") + \n",
    "     geom_text(data = swe_label,label = \"ns\",size=4,color=\"black\",fontface = \"italic\") + \n",
    "#      geom_text(data = zho_ns_label,label = \"ns\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "     geom_text(data = zho_label,label = \"^\",size=8, color=\"black\") +\n",
    "     ylim(0, 250) +\n",
    "     labs(tag = \"A\",\n",
    "          y = \"Number of Unique Words\", x = \"\") +\n",
    "     theme_classic() +\n",
    "     scale_x_discrete(labels= xlabs) +\n",
    "     theme(text = element_text(size=16),\n",
    "           axis.text.x = element_text(vjust = 0.5, hjust=.5),\n",
    "           legend.title = element_blank(),\n",
    "           legend.background = element_rect(fill=alpha(\"white\",0.90),\n",
    "                                                            size=0, linetype=\"dotted\",\n",
    "                                                            colour = \"white\"),\n",
    "           legend.text=element_text(size=16))\n",
    "     ggsave(\"../figures/lexical_diversity_rand.pdf\", width = 11.7, height = 6.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for manuscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i rand_lex_sumstats\n",
    "\n",
    "library('ggplot2')\n",
    "library('repr')\n",
    "options(repr.plot.width=6, repr.plot.height=12)\n",
    "\n",
    "xlabs <- c(\"C\", \"NC\")\n",
    "\n",
    "# ara_label <- data.frame(means=c(0),contingent = c(1.5),language=\"ara\") # no adult speech transcribed\n",
    "deu_label <- data.frame(sums=c(235),contingent = c(1.5),Language_name=\"German\")\n",
    "eng_label <- data.frame(sums=c(235),contingent = c(1.5),Language_name=\"English\")\n",
    "est_label <- data.frame(sums=c(235),contingent = c(1.5),Language_name=\"Estonian\")\n",
    "fas_label <- data.frame(sums=c(235),contingent = c(1.5),Language_name=\"Persian\")\n",
    "fra_label <- data.frame(sums=c(235),contingent = c(1.5),Language_name=\"French\")\n",
    "hrv_label <- data.frame(sums=c(235),contingent = c(1.5),Language_name=\"Croatian\")\n",
    "jpn_label <- data.frame(sums=c(235),contingent = c(1.5),Language_name=\"Japanese\")\n",
    "kor_label <- data.frame(sums=c(235),contingent = c(1.5),Language_name=\"Korean\")\n",
    "# nor_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"Norwegian\")\n",
    "nor_ns_label <- data.frame(sums=c(247),contingent = c(1.5),Language_name=\"Norwegian\")\n",
    "pol_ns_label <- data.frame(sums=c(247),contingent = c(1.5),Language_name=\"Polish\")\n",
    "por_label <- data.frame(sums=c(235),contingent = c(1.5),Language_name=\"Portuguese\")\n",
    "spa_ns_label <- data.frame(sums=c(247),contingent = c(1.5),Language_name=\"Spanish\")\n",
    "swe_label <- data.frame(sums=c(247),contingent = c(1.5),Language_name=\"Swedish\")\n",
    "zho_label <- data.frame(sums=c(235),contingent = c(1.5),Language_name=\"Mandarin\")\n",
    "# zho_ns_label <- data.frame(means=c(6),contingent = c(1.5),Language_name=\"Mandarin\")\n",
    "\n",
    "\n",
    "p <- ggplot(rand_lex_sumstats, aes(x = contingent, y = sums, color = Language_name)) +\n",
    "     stat_summary(fun.y=mean, geom=\"point\", shape=19, size=1.75) + \n",
    "     stat_summary(fun.data = mean_se, geom = \"errorbar\", size=1.25, width = .4) +\n",
    "     facet_wrap(. ~ Language_name,ncol = 7) + \n",
    "     geom_text(data = deu_label,label = \"***\",size=6,color=\"black\") + \n",
    "     geom_text(data = eng_label,label = \"***\",size=6,color=\"black\") +  \n",
    "     geom_text(data = est_label,label = \"**\",size=6,color=\"black\") +  \n",
    "     geom_text(data = fas_label,label = \"*\",size=6, color=\"black\") +\n",
    "     geom_text(data = fra_label,label = \"***\",size=6,color=\"black\") +  \n",
    "     geom_text(data = hrv_label,label = \"***\",size=6,color=\"black\") + \n",
    "     geom_text(data = jpn_label,label = \"***\",size=6,color=\"black\") + \n",
    "     geom_text(data = kor_label,label = \"***\",size=6,color=\"black\") +  \n",
    "     geom_text(data = nor_ns_label,label = \"ns\",size=3,color=\"black\",fontface = \"italic\") +  \n",
    "     geom_text(data = por_label,label = \"**\",size=6,color=\"black\") +  \n",
    "     geom_text(data = spa_ns_label,label = \"ns\",size=3,color=\"black\",fontface = \"italic\") + \n",
    "     geom_text(data = swe_label,label = \"ns\",size=3,color=\"black\",fontface = \"italic\") + \n",
    "     geom_text(data = zho_label,label = \"^\",size=3, color=\"black\") +\n",
    "     ylim(0, 250) +\n",
    "     labs(tag = \"A\",\n",
    "          y = \"Number of Unique Words\", x = \"\") +\n",
    "     theme_classic() +\n",
    "     scale_x_discrete(labels= xlabs) +\n",
    "     theme(text = element_text(size=11.5),\n",
    "           axis.text.x = element_text(vjust = 0.5, hjust=0.5),\n",
    "           legend.position=\"none\")\n",
    "     ggsave(\"../figures/figure_2_A.pdf\", width = 11.5, height = 4.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot + effect estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "deu_est_label <- data.frame(sums=c(.25),contingent = c(1),Language_name=\"German\")\n",
    "eng_est_label <- data.frame(sums=c(.25),contingent = c(1),Language_name=\"English\")\n",
    "est_est_label <- data.frame(sums=c(.25),contingent = c(1),Language_name=\"Estonian\")\n",
    "fas_est_label <- data.frame(sums=c(.25),contingent = c(1),Language_name=\"Persian\")\n",
    "fra_est_label <- data.frame(sums=c(.25),contingent = c(1),Language_name=\"French\")\n",
    "hrv_est_label <- data.frame(sums=c(.25),contingent = c(1),Language_name=\"Croatian\")\n",
    "jpn_est_label <- data.frame(sums=c(.25),contingent = c(1),Language_name=\"Japanese\")\n",
    "kor_est_label <- data.frame(sums=c(.25),contingent = c(1),Language_name=\"Korean\")\n",
    "nor_est_label <- data.frame(sums=c(.25),contingent = c(1),Language_name=\"Norwegian\")\n",
    "por_est_label <- data.frame(sums=c(.25),contingent = c(1),Language_name=\"Portuguese\")\n",
    "spa_est_label <- data.frame(sums=c(.25),contingent = c(1),Language_name=\"Spanish\")\n",
    "swe_est_label <- data.frame(sums=c(.25),contingent = c(1),Language_name=\"Swedish\")\n",
    "zho_est_label <- data.frame(sums=c(.25),contingent = c(1),Language_name=\"Mandarin\")\n",
    "\n",
    "p <- p + geom_text(data = deu_est_label,label = \"est=-66\",size=4,color=\"black\") +\n",
    "         geom_text(data = eng_est_label,label = \"est=-122\",size=4,color=\"black\") +\n",
    "         geom_text(data = est_est_label,label = \"est=-54.2\",size=4,color=\"black\") +\n",
    "         geom_text(data = fas_est_label,label = \"est=-51.1\",size=4,color=\"black\") +\n",
    "         geom_text(data = fra_est_label,label = \"est=-67.3\",size=4,color=\"black\") +\n",
    "         geom_text(data = hrv_est_label,label = \"est=-37.5\",size=4,color=\"black\") +\n",
    "         geom_text(data = jpn_est_label,label = \"est=-41.9\",size=4,color=\"black\") +\n",
    "         geom_text(data = kor_est_label,label = \"est=-101\",size=4,color=\"black\") +\n",
    "#          geom_text(data = nor_est_label,label = \"est=-.68\",size=4,color=\"black\") +\n",
    "         geom_text(data = por_est_label,label = \"est=-32.5\",size=4,color=\"black\") +\n",
    "#          geom_text(data = spa_est_label,label = \"est=-.39\",size=4,color=\"black\") +\n",
    "         geom_text(data = swe_est_label,label = \"est=-43.4\",size=4,color=\"black\") +\n",
    "         geom_text(data = zho_est_label,label = \"est=-60\",size=4,color=\"black\")\n",
    "         \n",
    "\n",
    "ggsave(\"../figures/lexical_diversity_rand_eff.pdf\", width = 11.7, height = 6.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\+ sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "deu_n_label <- data.frame(sums=c(.25),contingent = c(1.7),Language_name=\"German\")\n",
    "eng_n_label <- data.frame(sums=c(.25),contingent = c(1.7),Language_name=\"English\")\n",
    "est_n_label <- data.frame(sums=c(.25),contingent = c(1.7),Language_name=\"Estonian\")\n",
    "fas_n_label <- data.frame(sums=c(.25),contingent = c(1.7),Language_name=\"Persian\")\n",
    "fra_n_label <- data.frame(sums=c(.25),contingent = c(1.7),Language_name=\"French\")\n",
    "hrv_n_label <- data.frame(sums=c(.25),contingent = c(1.7),Language_name=\"Croatian\")\n",
    "jpn_n_label <- data.frame(sums=c(.25),contingent = c(1.7),Language_name=\"Japanese\")\n",
    "kor_n_label <- data.frame(sums=c(.25),contingent = c(1.7),Language_name=\"Korean\")\n",
    "nor_n_label <- data.frame(sums=c(.25),contingent = c(1.7),Language_name=\"Norwegian\")\n",
    "pol_n_label <- data.frame(sums=c(.25),contingent = c(1.7),Language_name=\"Polish\")\n",
    "por_n_label <- data.frame(sums=c(.25),contingent = c(1.7),Language_name=\"Portuguese\")\n",
    "spa_n_label <- data.frame(sums=c(.25),contingent = c(1.7),Language_name=\"Spanish\")\n",
    "swe_n_label <- data.frame(sums=c(.25),contingent = c(1.7),Language_name=\"Swedish\")\n",
    "zho_n_label <- data.frame(sums=c(.25),contingent = c(1.7),Language_name=\"Mandarin\")\n",
    "\n",
    "deu_sz_label <- data.frame(sums=c(.25),contingent = c(2.1),Language_name=\"German\")\n",
    "eng_sz_label <- data.frame(sums=c(.25),contingent = c(2.1),Language_name=\"English\")\n",
    "est_sz_label <- data.frame(sums=c(.25),contingent = c(2.1),Language_name=\"Estonian\")\n",
    "fas_sz_label <- data.frame(sums=c(.25),contingent = c(2.1),Language_name=\"Persian\")\n",
    "fra_sz_label <- data.frame(sums=c(.25),contingent = c(2.1),Language_name=\"French\")\n",
    "hrv_sz_label <- data.frame(sums=c(.25),contingent = c(2.1),Language_name=\"Croatian\")\n",
    "jpn_sz_label <- data.frame(sums=c(.25),contingent = c(2.1),Language_name=\"Japanese\")\n",
    "kor_sz_label <- data.frame(sums=c(.25),contingent = c(2.1),Language_name=\"Korean\")\n",
    "nor_sz_label <- data.frame(sums=c(.25),contingent = c(2.1),Language_name=\"Norwegian\")\n",
    "pol_sz_label <- data.frame(sums=c(.25),contingent = c(2.1),Language_name=\"Polish\")\n",
    "por_sz_label <- data.frame(sums=c(.25),contingent = c(2.1),Language_name=\"Portuguese\")\n",
    "spa_sz_label <- data.frame(sums=c(.25),contingent = c(2.1),Language_name=\"Spanish\")\n",
    "swe_sz_label <- data.frame(sums=c(.25),contingent = c(2.1),Language_name=\"Swedish\")\n",
    "zho_sz_label <- data.frame(sums=c(.25),contingent = c(2.1),Language_name=\"Mandarin\")\n",
    "\n",
    "p <- p + geom_text(data = deu_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = eng_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = est_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = fas_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = fra_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = hrv_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = jpn_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = kor_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = nor_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = pol_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = por_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = spa_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = swe_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = zho_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = deu_sz_label,label = \" = 39\",size=4,color=\"black\") +\n",
    "         geom_text(data = eng_sz_label,label = \" = 1005\",size=4,color=\"black\") +\n",
    "         geom_text(data = est_sz_label,label = \" = 22\",size=4,color=\"black\") +\n",
    "         geom_text(data = fas_sz_label,label = \" = 12\",size=4,color=\"black\") +\n",
    "         geom_text(data = fra_sz_label,label = \" = 303\",size=4,color=\"black\") +\n",
    "         geom_text(data = hrv_sz_label,label = \" = 79\",size=4,color=\"black\") +\n",
    "         geom_text(data = jpn_sz_label,label = \" = 139\",size=4,color=\"black\") +\n",
    "         geom_text(data = kor_sz_label,label = \" = 37\",size=4,color=\"black\") +\n",
    "         geom_text(data = nor_sz_label,label = \" = 56\",size=4,color=\"black\") +\n",
    "         geom_text(data = pol_sz_label,label = \" = 1\",size=4,color=\"black\") +\n",
    "         geom_text(data = por_sz_label,label = \" = 24\",size=4,color=\"black\") +\n",
    "         geom_text(data = spa_sz_label,label = \" = 31\",size=4,color=\"black\") +\n",
    "         geom_text(data = swe_sz_label,label = \" = 16\",size=4,color=\"black\") +\n",
    "         geom_text(data = zho_sz_label,label = \" = 2\",size=4,color=\"black\")\n",
    "         \n",
    "\n",
    "ggsave(\"../figures/lexical_diversity_rand_eff_n.pdf\", width = 11.7, height = 6.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### Lexical diversity mixed models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ara=rand_dat_inc_cg[['language','num_tokens','contingent','transcript_id','target_child_id']][rand_dat_inc_cg[\"language\"]==\"ara\"] # no adult speech transcribed\n",
    "deu=rand_lex_sumstats[['Language_name','sums','contingent','transcript_id','target_child_id']][rand_lex_sumstats[\"Language_name\"]==\"German\"]\n",
    "eng=rand_lex_sumstats[['Language_name','sums','contingent','transcript_id','target_child_id']][rand_lex_sumstats[\"Language_name\"]==\"English\"]\n",
    "est=rand_lex_sumstats[['Language_name','sums','contingent','transcript_id','target_child_id']][rand_lex_sumstats[\"Language_name\"]==\"Estonian\"]\n",
    "fas=rand_lex_sumstats[['Language_name','sums','contingent','transcript_id','target_child_id']][rand_lex_sumstats[\"Language_name\"]==\"Persian\"]\n",
    "fra=rand_lex_sumstats[['Language_name','sums','contingent','transcript_id','target_child_id']][rand_lex_sumstats[\"Language_name\"]==\"French\"]\n",
    "hrv=rand_lex_sumstats[['Language_name','sums','contingent','transcript_id','target_child_id']][rand_lex_sumstats[\"Language_name\"]==\"Croatian\"]\n",
    "jpn=rand_lex_sumstats[['Language_name','sums','contingent','transcript_id','target_child_id']][rand_lex_sumstats[\"Language_name\"]==\"Japanese\"]\n",
    "kor=rand_lex_sumstats[['Language_name','sums','contingent','transcript_id','target_child_id']][rand_lex_sumstats[\"Language_name\"]==\"Korean\"]\n",
    "nor=rand_lex_sumstats[['Language_name','sums','contingent','transcript_id','target_child_id']][rand_lex_sumstats[\"Language_name\"]==\"Norwegian\"]\n",
    "pol=rand_lex_sumstats[['Language_name','sums','contingent','transcript_id','target_child_id']][rand_lex_sumstats[\"Language_name\"]==\"Polish\"]\n",
    "por=rand_lex_sumstats[['Language_name','sums','contingent','transcript_id','target_child_id']][rand_lex_sumstats[\"Language_name\"]==\"Portuguese\"]\n",
    "spa=rand_lex_sumstats[['Language_name','sums','contingent','transcript_id','target_child_id']][rand_lex_sumstats[\"Language_name\"]==\"Spanish\"]\n",
    "swe=rand_lex_sumstats[['Language_name','sums','contingent','transcript_id','target_child_id']][rand_lex_sumstats[\"Language_name\"]==\"Swedish\"]\n",
    "zho=rand_lex_sumstats[['Language_name','sums','contingent','transcript_id','target_child_id']][rand_lex_sumstats[\"Language_name\"]==\"Mandarin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: Matrix\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: ‘lmerTest’\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from ‘package:lme4’:\n",
      "\n",
      "    lmer\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from ‘package:stats’:\n",
      "\n",
      "    step\n",
      "\n",
      "\n",
      "R[write to console]: ── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.1 ──\n",
      "\n",
      "R[write to console]: \u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.1.6     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.7\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.1.4     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 2.1.1     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4     \n",
      "\n",
      "R[write to console]: ── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mtidyr\u001b[39m::\u001b[32mexpand()\u001b[39m masks \u001b[34mMatrix\u001b[39m::expand()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mtidyr\u001b[39m::\u001b[32mpack()\u001b[39m   masks \u001b[34mMatrix\u001b[39m::pack()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mtidyr\u001b[39m::\u001b[32munpack()\u001b[39m masks \u001b[34mMatrix\u001b[39m::unpack()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "library(\"lme4\")\n",
    "library(\"emmeans\")\n",
    "library(\"lmerTest\")\n",
    "library(\"tidyverse\")\n",
    "\n",
    "effect_sizes <- data.frame(matrix(ncol = 2, nrow = 0))\n",
    "cols <- c(\"Language_name\", \"rand_effect_size\")\n",
    "colnames(effect_sizes) <- cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Cannot use mode = \"kenward-roger\" because *pbkrtest* package is not installed\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate   SE df t.ratio p.value\n",
      " contingent - (non-contingent)      -62 7.81 38  -7.946  <.0001\n",
      "\n",
      "Degrees-of-freedom method: satterthwaite \n",
      "\n",
      "[[2]]\n",
      "[1] 1.340226e-09\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Since 'object' is a list, we are using the contrasts already present.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language_name  rand_effect_size\n",
      "1        German -1.82300800568462\n"
     ]
    }
   ],
   "source": [
    "%%R -i deu\n",
    "\n",
    "lm2 <- lmer(sums ~ contingent + (1|target_child_id) + (1|transcript_id),data=deu, REML= FALSE)\n",
    "emm2<-emmeans(lm2,pairwise~contingent)\n",
    "pval<-summary(emm2$contrasts)$p.value\n",
    "print(c(emm2$contrasts, pval))\n",
    "p.adjust(pval, \"holm\", 14) # create big vector of p-values and ajdust those\n",
    "# summary(emmeans(lm2,\"contingent\",contr=\"pairwise\"),infer=TRUE) #group means\n",
    "# test(contrast(emmeans(lm2,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "deu_lname <- deu$Language_name[1]\n",
    "\n",
    "deu_eff <- eff_size(emm2,sigma = sigma(lm2), edf = df.residual(lm2))\n",
    "\n",
    "deu_eff <- summary(deu_eff)$effect.size\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(deu_lname,deu_eff)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: boundary (singular) fit: see ?isSingular\n",
      "\n",
      "R[write to console]: Cannot use mode = \"kenward-roger\" because *pbkrtest* package is not installed\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate   SE   df t.ratio p.value\n",
      " contingent - (non-contingent)     -108 2.02 1676 -53.506  <.0001\n",
      "\n",
      "Degrees-of-freedom method: satterthwaite \n",
      "\n",
      "[[2]]\n",
      "[1] 1.49647e-12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Since 'object' is a list, we are using the contrasts already present.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language_name  rand_effect_size\n",
      "1        German -1.82300800568462\n",
      "2       English -2.46968244455422\n"
     ]
    }
   ],
   "source": [
    "%%R -i eng\n",
    "\n",
    "lm3 <- lmer(sums ~ contingent + (1|target_child_id) + (1|transcript_id),data=eng, REML= FALSE)\n",
    "emm3<-emmeans(lm3,pairwise~contingent)\n",
    "pval<-summary(emm3$contrasts)$p.value\n",
    "print(c(emm3$contrasts, pval))\n",
    "p.adjust(pval, \"holm\", 14)\n",
    "# summary(emmeans(lm3,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm3,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "eng_lname <- eng$Language_name[1]\n",
    "\n",
    "eng_eff <- eff_size(emm3,sigma = sigma(lm3), edf = df.residual(lm3))\n",
    "\n",
    "eng_eff <- summary(eng_eff)$effect.size\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(eng_lname,eng_eff)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: boundary (singular) fit: see ?isSingular\n",
      "\n",
      "R[write to console]: Cannot use mode = \"kenward-roger\" because *pbkrtest* package is not installed\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate   SE df t.ratio p.value\n",
      " contingent - (non-contingent)      -59 13.6 22  -4.329  0.0003\n",
      "\n",
      "Degrees-of-freedom method: satterthwaite \n",
      "\n",
      "[[2]]\n",
      "[1] 0.0002698171\n",
      "\n",
      "[1] 0.003777439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Since 'object' is a list, we are using the contrasts already present.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language_name  rand_effect_size\n",
      "1        German -1.82300800568462\n",
      "2       English -2.46968244455422\n",
      "3      Estonian  -1.3053776625777\n"
     ]
    }
   ],
   "source": [
    "%%R -i est\n",
    "\n",
    "lm4 <- lmer(sums ~ contingent + (1|target_child_id) + (1|transcript_id),data=est, REML= FALSE)\n",
    "emm4<-emmeans(lm4,pairwise~contingent)\n",
    "pval<-summary(emm4$contrasts)$p.value\n",
    "print(c(emm4$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm4,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm4,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "est_lname <- est$Language_name[1]\n",
    "\n",
    "est_eff <- eff_size(emm4,sigma = sigma(lm4), edf = df.residual(lm4))\n",
    "\n",
    "est_eff <- summary(est_eff)$effect.size\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(est_lname,est_eff)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Cannot use mode = \"kenward-roger\" because *pbkrtest* package is not installed\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate   SE df t.ratio p.value\n",
      " contingent - (non-contingent)      -67 10.2 10  -6.556  0.0001\n",
      "\n",
      "Degrees-of-freedom method: satterthwaite \n",
      "\n",
      "[[2]]\n",
      "[1] 6.423789e-05\n",
      "\n",
      "[1] 0.0008993305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Since 'object' is a list, we are using the contrasts already present.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language_name  rand_effect_size\n",
      "1        German -1.82300800568462\n",
      "2       English -2.46968244455422\n",
      "3      Estonian  -1.3053776625777\n",
      "4       Persian -2.93194866482665\n"
     ]
    }
   ],
   "source": [
    "%%R -i fas\n",
    "\n",
    "lm5 <- lmer(sums ~ contingent + (1|transcript_id),data=fas, REML= FALSE)\n",
    "emm5<-emmeans(lm5,pairwise~contingent)\n",
    "pval<-summary(emm5$contrasts)$p.value\n",
    "print(c(emm5$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm5,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm5,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "fas_lname <- fas$Language_name[1]\n",
    "\n",
    "fas_eff <- eff_size(emm5,sigma = sigma(lm5), edf = df.residual(lm5))\n",
    "\n",
    "fas_eff <- summary(fas_eff)$effect.size\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(fas_lname,fas_eff)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Cannot use mode = \"kenward-roger\" because *pbkrtest* package is not installed\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate   SE  df t.ratio p.value\n",
      " contingent - (non-contingent)    -68.9 3.35 279 -20.583  <.0001\n",
      "\n",
      "Degrees-of-freedom method: satterthwaite \n",
      "\n",
      "[[2]]\n",
      "[1] 3.597123e-13\n",
      "\n",
      "[1] 5.035972e-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Since 'object' is a list, we are using the contrasts already present.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language_name  rand_effect_size\n",
      "1        German -1.82300800568462\n",
      "2       English -2.46968244455422\n",
      "3      Estonian  -1.3053776625777\n",
      "4       Persian -2.93194866482665\n",
      "5        French -1.73890442295843\n"
     ]
    }
   ],
   "source": [
    "%%R -i fra\n",
    "\n",
    "lm6 <- lmer(sums ~ contingent + (1|target_child_id) + (1|transcript_id),data=fra, REML= FALSE)\n",
    "emm6<-emmeans(lm6,pairwise~contingent)\n",
    "pval<-summary(emm6$contrasts)$p.value\n",
    "print(c(emm6$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm6,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm6,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "fra_lname <- fra$Language_name[1]\n",
    "\n",
    "fra_eff <- eff_size(emm6,sigma = sigma(lm6), edf = df.residual(lm6))\n",
    "\n",
    "fra_eff <- summary(fra_eff)$effect.size\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(fra_lname,fra_eff)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Cannot use mode = \"kenward-roger\" because *pbkrtest* package is not installed\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate   SE df t.ratio p.value\n",
      " contingent - (non-contingent)    -40.2 4.26 56  -9.437  <.0001\n",
      "\n",
      "Degrees-of-freedom method: satterthwaite \n",
      "\n",
      "[[2]]\n",
      "[1] 7.681744e-12\n",
      "\n",
      "[1] 1.075444e-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Since 'object' is a list, we are using the contrasts already present.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language_name  rand_effect_size\n",
      "1        German -1.82300800568462\n",
      "2       English -2.46968244455422\n",
      "3      Estonian  -1.3053776625777\n",
      "4       Persian -2.93194866482665\n",
      "5        French -1.73890442295843\n",
      "6      Croatian -1.78338336898637\n"
     ]
    }
   ],
   "source": [
    "%%R -i hrv\n",
    "\n",
    "lm7 <- lmer(sums ~ contingent + (1|target_child_id) + (1|transcript_id),data=hrv, REML= FALSE)\n",
    "emm7<-emmeans(lm7,pairwise~contingent)\n",
    "pval<-summary(emm7$contrasts)$p.value\n",
    "print(c(emm7$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm7,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm7,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "hrv_lname <- hrv$Language_name[1]\n",
    "\n",
    "hrv_eff <- eff_size(emm7,sigma = sigma(lm7), edf = df.residual(lm7))\n",
    "\n",
    "hrv_eff <- summary(hrv_eff)$effect.size\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(hrv_lname,hrv_eff)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Cannot use mode = \"kenward-roger\" because *pbkrtest* package is not installed\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate   SE  df t.ratio p.value\n",
      " contingent - (non-contingent)    -42.7 3.03 139 -14.064  <.0001\n",
      "\n",
      "Degrees-of-freedom method: satterthwaite \n",
      "\n",
      "[[2]]\n",
      "[1] 0\n",
      "\n",
      "[1] 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Since 'object' is a list, we are using the contrasts already present.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language_name  rand_effect_size\n",
      "1        German -1.82300800568462\n",
      "2       English -2.46968244455422\n",
      "3      Estonian  -1.3053776625777\n",
      "4       Persian -2.93194866482665\n",
      "5        French -1.73890442295843\n",
      "6      Croatian -1.78338336898637\n",
      "7      Japanese -1.68699142881437\n"
     ]
    }
   ],
   "source": [
    "%%R -i jpn\n",
    "\n",
    "lm8 <- lmer(sums ~ contingent + (1|target_child_id) + (1|transcript_id),data=jpn, REML= FALSE)\n",
    "emm8<-emmeans(lm8,pairwise~contingent)\n",
    "pval<-summary(emm8$contrasts)$p.value\n",
    "print(c(emm8$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm8,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm8,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "jpn_lname <- jpn$Language_name[1]\n",
    "\n",
    "jpn_eff <- eff_size(emm8,sigma = sigma(lm8), edf = df.residual(lm8))\n",
    "\n",
    "jpn_eff <- summary(jpn_eff)$effect.size\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(jpn_lname,jpn_eff)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: boundary (singular) fit: see ?isSingular\n",
      "\n",
      "R[write to console]: Cannot use mode = \"kenward-roger\" because *pbkrtest* package is not installed\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate   SE df t.ratio p.value\n",
      " contingent - (non-contingent)     -112 13.9 56  -8.054  <.0001\n",
      "\n",
      "Degrees-of-freedom method: satterthwaite \n",
      "\n",
      "[[2]]\n",
      "[1] 7.023804e-11\n",
      "\n",
      "[1] 9.833325e-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Since 'object' is a list, we are using the contrasts already present.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language_name  rand_effect_size\n",
      "1        German -1.82300800568462\n",
      "2       English -2.46968244455422\n",
      "3      Estonian  -1.3053776625777\n",
      "4       Persian -2.93194866482665\n",
      "5        French -1.73890442295843\n",
      "6      Croatian -1.78338336898637\n",
      "7      Japanese -1.68699142881437\n",
      "8        Korean -2.15263727391117\n"
     ]
    }
   ],
   "source": [
    "%%R -i kor\n",
    "\n",
    "lm9 <- lmer(sums ~ contingent + (1|transcript_id), data=kor, REML= FALSE)\n",
    "emm9<-emmeans(lm9,pairwise~contingent)\n",
    "pval<-summary(emm9$contrasts)$p.value\n",
    "print(c(emm9$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm9,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm9,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "kor_lname <- kor$Language_name[1]\n",
    "\n",
    "kor_eff <- eff_size(emm9,sigma = sigma(lm9), edf = df.residual(lm9))\n",
    "\n",
    "kor_eff <- summary(kor_eff)$effect.size\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(kor_lname,kor_eff)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: boundary (singular) fit: see ?isSingular\n",
      "\n",
      "R[write to console]: Cannot use mode = \"kenward-roger\" because *pbkrtest* package is not installed\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate   SE   df t.ratio p.value\n",
      " contingent - (non-contingent)    -22.9 8.35 37.1  -2.739  0.0094\n",
      "\n",
      "Degrees-of-freedom method: satterthwaite \n",
      "\n",
      "[[2]]\n",
      "[1] 0.009417298\n",
      "\n",
      "[1] 0.1318422\n",
      "  Language_name  rand_effect_size\n",
      "1        German -1.82300800568462\n",
      "2       English -2.46968244455422\n",
      "3      Estonian  -1.3053776625777\n",
      "4       Persian -2.93194866482665\n",
      "5        French -1.73890442295843\n",
      "6      Croatian -1.78338336898637\n",
      "7      Japanese -1.68699142881437\n",
      "8        Korean -2.15263727391117\n",
      "9     Norwegian               NaN\n"
     ]
    }
   ],
   "source": [
    "%%R -i nor\n",
    "\n",
    "lm10 <- lmer(sums ~ contingent + (1|target_child_id) + (1|transcript_id),data=nor, REML= FALSE)\n",
    "emm10<-emmeans(lm10,pairwise~contingent)\n",
    "pval<-summary(emm10$contrasts)$p.value\n",
    "print(c(emm10$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm10,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm10,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "nor_lname <- nor$Language_name[1]\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(nor_lname,NaN)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate  SE df t.ratio p.value\n",
      " contingent - (non-contingent)      -21 NaN  0     NaN     NaN\n",
      "\n",
      "\n",
      "[[2]]\n",
      "[1] NaN\n",
      "\n",
      "[1] NaN\n",
      "   Language_name  rand_effect_size\n",
      "1         German -1.82300800568462\n",
      "2        English -2.46968244455422\n",
      "3       Estonian  -1.3053776625777\n",
      "4        Persian -2.93194866482665\n",
      "5         French -1.73890442295843\n",
      "6       Croatian -1.78338336898637\n",
      "7       Japanese -1.68699142881437\n",
      "8         Korean -2.15263727391117\n",
      "9      Norwegian               NaN\n",
      "10        Polish               NaN\n"
     ]
    }
   ],
   "source": [
    "%%R -i pol\n",
    "\n",
    "# simple linear model (no random effects, because only 1 transcript from 1 sub)\n",
    "\n",
    "#\n",
    "\n",
    "lm11 <- lm(sums ~ contingent ,data=pol, REML= FALSE)\n",
    "emm11<-emmeans(lm11,pairwise~contingent)\n",
    "pval<-summary(emm11$contrasts)$p.value\n",
    "print(c(emm11$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm11,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm11,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "pol_lname <- pol$Language_name[1]\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(pol_lname,NaN)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Cannot use mode = \"kenward-roger\" because *pbkrtest* package is not installed\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate  SE df t.ratio p.value\n",
      " contingent - (non-contingent)    -44.8 9.4 23  -4.766  0.0001\n",
      "\n",
      "Degrees-of-freedom method: satterthwaite \n",
      "\n",
      "[[2]]\n",
      "[1] 8.350929e-05\n",
      "\n",
      "[1] 0.00116913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Since 'object' is a list, we are using the contrasts already present.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Language_name  rand_effect_size\n",
      "1         German -1.82300800568462\n",
      "2        English -2.46968244455422\n",
      "3       Estonian  -1.3053776625777\n",
      "4        Persian -2.93194866482665\n",
      "5         French -1.73890442295843\n",
      "6       Croatian -1.78338336898637\n",
      "7       Japanese -1.68699142881437\n",
      "8         Korean -2.15263727391117\n",
      "9      Norwegian               NaN\n",
      "10        Polish               NaN\n",
      "11    Portuguese  -1.4052872748849\n"
     ]
    }
   ],
   "source": [
    "%%R -i por\n",
    "\n",
    "lm12 <- lmer(sums ~ contingent + (1|target_child_id) + (1|transcript_id),data=por, REML= FALSE)\n",
    "emm12<-emmeans(lm12,pairwise~contingent)\n",
    "pval<-summary(emm12$contrasts)$p.value\n",
    "print(c(emm12$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm12,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm12,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "por_lname <- por$Language_name[1]\n",
    "\n",
    "por_eff <- eff_size(emm12,sigma = sigma(lm12), edf = df.residual(lm12))\n",
    "\n",
    "por_eff <- summary(por_eff)$effect.size\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(por_lname,por_eff)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Cannot use mode = \"kenward-roger\" because *pbkrtest* package is not installed\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate   SE df t.ratio p.value\n",
      " contingent - (non-contingent)    -3.97 5.12 31  -0.776  0.4438\n",
      "\n",
      "Degrees-of-freedom method: satterthwaite \n",
      "\n",
      "[[2]]\n",
      "[1] 0.4438368\n",
      "\n",
      "[1] 1\n",
      "   Language_name  rand_effect_size\n",
      "1         German -1.82300800568462\n",
      "2        English -2.46968244455422\n",
      "3       Estonian  -1.3053776625777\n",
      "4        Persian -2.93194866482665\n",
      "5         French -1.73890442295843\n",
      "6       Croatian -1.78338336898637\n",
      "7       Japanese -1.68699142881437\n",
      "8         Korean -2.15263727391117\n",
      "9      Norwegian               NaN\n",
      "10        Polish               NaN\n",
      "11    Portuguese  -1.4052872748849\n",
      "12       Spanish               NaN\n"
     ]
    }
   ],
   "source": [
    "%%R -i spa\n",
    "\n",
    "lm13 <- lmer(sums ~ contingent + (1|target_child_id) + (1|transcript_id),data=spa, REML= FALSE)\n",
    "emm13<-emmeans(lm13,pairwise~contingent)\n",
    "pval<-summary(emm13$contrasts)$p.value\n",
    "print(c(emm13$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm13,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm13,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "spa_lname <- spa$Language_name[1]\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(spa_lname,NaN)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: boundary (singular) fit: see ?isSingular\n",
      "\n",
      "R[write to console]: Cannot use mode = \"kenward-roger\" because *pbkrtest* package is not installed\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate   SE df t.ratio p.value\n",
      " contingent - (non-contingent)    -37.1 12.9 16  -2.882  0.0108\n",
      "\n",
      "Degrees-of-freedom method: satterthwaite \n",
      "\n",
      "[[2]]\n",
      "[1] 0.01083042\n",
      "\n",
      "[1] 0.1516259\n",
      "   Language_name  rand_effect_size\n",
      "1         German -1.82300800568462\n",
      "2        English -2.46968244455422\n",
      "3       Estonian  -1.3053776625777\n",
      "4        Persian -2.93194866482665\n",
      "5         French -1.73890442295843\n",
      "6       Croatian -1.78338336898637\n",
      "7       Japanese -1.68699142881437\n",
      "8         Korean -2.15263727391117\n",
      "9      Norwegian               NaN\n",
      "10        Polish               NaN\n",
      "11    Portuguese  -1.4052872748849\n",
      "12       Spanish               NaN\n",
      "13       Swedish               NaN\n"
     ]
    }
   ],
   "source": [
    "%%R -i swe\n",
    "\n",
    "lm14 <- lmer(sums ~ contingent + (1|target_child_id) + (1|transcript_id),data=swe, REML= FALSE)\n",
    "emm14<-emmeans(lm14,pairwise~contingent)\n",
    "pval<-summary(emm14$contrasts)$p.value\n",
    "print(c(emm14$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm14,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm14,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "swe_lname <- swe$Language_name[1]\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(swe_lname,NaN)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Cannot use mode = \"kenward-roger\" because *pbkrtest* package is not installed\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate   SE df t.ratio p.value\n",
      " contingent - (non-contingent)      -92 12.7  2  -7.228  0.0185\n",
      "\n",
      "Degrees-of-freedom method: satterthwaite \n",
      "\n",
      "[[2]]\n",
      "[1] 0.01847086\n",
      "\n",
      "[1] 0.258592\n"
     ]
    }
   ],
   "source": [
    "%%R -i zho\n",
    "\n",
    "lm15 <- lmer(sums ~ contingent + (1|transcript_id),data=zho, REML= FALSE)\n",
    "emm15<-emmeans(lm15,pairwise~contingent)\n",
    "pval<-summary(emm15$contrasts)$p.value\n",
    "print(c(emm15$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm15,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm15,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "# zho_lname <- zho$Language_name[1]\n",
    "\n",
    "# zho_eff <- eff_size(emm15,sigma = sigma(lm15), edf = df.residual(lm15))\n",
    "\n",
    "# zho_eff <- summary(zho_eff)$effect.size\n",
    "\n",
    "# effect_sizes[nrow(effect_sizes)+1,] <- c(zho_lname,zho_eff)\n",
    "# effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "write.csv(x=effect_sizes,'../data/lexdiv_effect_sizes.csv', row.names = FALSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
