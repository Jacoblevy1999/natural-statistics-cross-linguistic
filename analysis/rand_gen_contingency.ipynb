{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Statistics Cross-linguistic\n",
    "\n",
    "Random samples contingency variable generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, \"data_proc\")\n",
    "import contingent_extraction\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rand_dat = pd.read_csv(\"../data/rand_dat.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rand_dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "#### How many languages are we analyzing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_dat[\"language\"].unique() # list of all langauges across corpora\n",
    "int_rand_dat = rand_dat[~rand_dat[\"language\"].str.contains(\"eng\")]\n",
    "int_rand_dat[\"language\"].unique() # list of all languages that don't contain `eng` in language name\n",
    "len(int_rand_dat[\"language\"].unique()) # language count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15 languages + 1 (`eng`) - 1 (`por swe`). Thus, **15 langauges**! `por swe` (Portugese and Swedish) is removed because we will only analyze monolingual corpora first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "#### How many participants are we analyzing?\n",
    "\n",
    "Get only monolingual corpora to finalize rand_dat dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_rand_dat = rand_dat[rand_dat[\"language\"]==\"eng\"] # only english\n",
    "rand_dat_inc = eng_rand_dat.append(int_rand_dat) # english and non-english\n",
    "rand_dat_inc = rand_dat_inc[rand_dat_inc[\"language\"]!= \"por swe\"]# exclude bilingual (por swe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_dat_inc = pd.read_csv(\"../data/rand_dat.csv\",index_col=0,low_memory=False)\n",
    "rand_dat_inc=rand_dat_inc[rand_dat_inc[\"language\"]!=\"ara\"]\n",
    "rand_dat_inc=rand_dat_inc[(rand_dat_inc[\"target_child_age\"]>=5) & (rand_dat_inc[\"target_child_age\"]<=30)]# exclude under 5- and over 30-month-olds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create language_name column\n",
    "\n",
    "language_labels = pd.read_csv(\"../data/language_labels.csv\")\n",
    "\n",
    "language_labels=language_labels.rename(columns={\"Language\":\"language\"})\n",
    "\n",
    "rand_dat_inc=rand_dat_inc.merge(language_labels,on='language',how=\"right\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 14 different monolingual languages in this dataset.\n",
      "There are 427 infants in this dataset.\n",
      "There are 1771 different transcripts in this dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"There are\", \n",
    "      len(rand_dat_inc[\"language\"].unique()),\n",
    "      \"different monolingual languages in this dataset.\")\n",
    "\n",
    "print(\"There are\",\n",
    "      len(rand_dat_inc[\"target_child_id\"].unique()),\n",
    "      \"infants in this dataset.\")\n",
    "\n",
    "print(\"There are\",\n",
    "      len(rand_dat_inc[\"transcript_id\"].unique()),\n",
    "      \"different transcripts in this dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | language   |   count |\n",
      "|---:|:-----------|--------:|\n",
      "|  0 | deu        |       4 |\n",
      "|  1 | eng        |     379 |\n",
      "|  2 | est        |       3 |\n",
      "|  3 | fas        |       1 |\n",
      "|  4 | fra        |      17 |\n",
      "|  5 | hrv        |       3 |\n",
      "|  6 | jpn        |       6 |\n",
      "|  7 | kor        |       1 |\n",
      "|  8 | nor        |       3 |\n",
      "|  9 | pol        |       1 |\n",
      "| 10 | por        |       2 |\n",
      "| 11 | spa        |       3 |\n",
      "| 12 | swe        |       3 |\n",
      "| 13 | zho        |       1 |\n"
     ]
    }
   ],
   "source": [
    "# how many children per language\n",
    "child_counts = rand_dat_inc.groupby(['language','target_child_id']).nunique()\n",
    "count_table = child_counts.groupby(['language']).size().to_frame('count').reset_index()\n",
    "print(count_table.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | Language_name   |   count |\n",
      "|---:|:----------------|--------:|\n",
      "|  0 | Croatian        |      79 |\n",
      "|  1 | English         |    1010 |\n",
      "|  2 | Estonian        |      22 |\n",
      "|  3 | French          |     303 |\n",
      "|  4 | German          |      39 |\n",
      "|  5 | Japanese        |     139 |\n",
      "|  6 | Korean          |      37 |\n",
      "|  7 | Mandarin        |       2 |\n",
      "|  8 | Norwegian       |      56 |\n",
      "|  9 | Persian         |      12 |\n",
      "| 10 | Polish          |       1 |\n",
      "| 11 | Portuguese      |      24 |\n",
      "| 12 | Spanish         |      31 |\n",
      "| 13 | Swedish         |      16 |\n"
     ]
    }
   ],
   "source": [
    "# how many transcripts per language\n",
    "transcript_counts = rand_dat_inc.groupby(['Language_name','transcript_id']).nunique()\n",
    "count_table = transcript_counts.groupby(['Language_name']).size().to_frame('count').reset_index()\n",
    "print(count_table.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# how many transcripts per language\n",
    "transcript_x_child_counts = rand_dat_inc.groupby(['language','transcript_id','target_child_id']).nunique()\n",
    "transcript_x_child_count_table = transcript_x_child_counts.groupby(['language','target_child_id']).size().to_frame('count').reset_index()\n",
    "# print(transcript_x_child_count_table.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# distribution of age groups\n",
    "ages = rand_dat_inc['target_child_age']\n",
    "ages.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | 0            |\n",
      "|---:|:-------------|\n",
      "|  0 | Leo          |\n",
      "|  1 | Rigol        |\n",
      "|  2 | Bernstein    |\n",
      "|  3 | Peters       |\n",
      "|  4 | Rollins      |\n",
      "|  5 | Bloom        |\n",
      "|  6 | Brent        |\n",
      "|  7 | Nelson       |\n",
      "|  8 | Braunwald    |\n",
      "|  9 | Soderstrom   |\n",
      "| 10 | Sachs        |\n",
      "| 11 | McCune       |\n",
      "| 12 | NewmanRatner |\n",
      "| 13 | MacWhinney   |\n",
      "| 14 | Providence   |\n",
      "| 15 | Argus        |\n",
      "| 16 | Zupping      |\n",
      "| 17 | Family       |\n",
      "| 18 | York         |\n",
      "| 19 | Lyon         |\n",
      "| 20 | Yamaguchi    |\n",
      "| 21 | Paris        |\n",
      "| 22 | Hunkeler     |\n",
      "| 23 | Kovacevic    |\n",
      "| 24 | Ishii        |\n",
      "| 25 | MiiPro       |\n",
      "| 26 | Miyata       |\n",
      "| 27 | Ryu          |\n",
      "| 28 | Garmann      |\n",
      "| 29 | WeistJarosz  |\n",
      "| 30 | Santos       |\n",
      "| 31 | Nieva        |\n",
      "| 32 | Remedi       |\n",
      "| 33 | Lund         |\n",
      "| 34 | Andren       |\n",
      "| 35 | Tong         |\n"
     ]
    }
   ],
   "source": [
    "# how many corpora\n",
    "corpora = pd.DataFrame(rand_dat_inc[\"corpus_name\"].unique())\n",
    "print(corpora.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | Language_name   | corpus_name   |\n",
      "|---:|:----------------|:--------------|\n",
      "|  0 | Croatian        | Kovacevic     |\n",
      "|  1 | English         | Bernstein     |\n",
      "|  2 | English         | Bloom         |\n",
      "|  3 | English         | Braunwald     |\n",
      "|  4 | English         | Brent         |\n",
      "|  5 | English         | MacWhinney    |\n",
      "|  6 | English         | McCune        |\n",
      "|  7 | English         | Nelson        |\n",
      "|  8 | English         | NewmanRatner  |\n",
      "|  9 | English         | Peters        |\n",
      "| 10 | English         | Providence    |\n",
      "| 11 | English         | Rollins       |\n",
      "| 12 | English         | Sachs         |\n",
      "| 13 | English         | Soderstrom    |\n",
      "| 14 | Estonian        | Argus         |\n",
      "| 15 | Estonian        | Zupping       |\n",
      "| 16 | French          | Hunkeler      |\n",
      "| 17 | French          | Lyon          |\n",
      "| 18 | French          | Paris         |\n",
      "| 19 | French          | Yamaguchi     |\n",
      "| 20 | French          | York          |\n",
      "| 21 | German          | Leo           |\n",
      "| 22 | German          | Rigol         |\n",
      "| 23 | Japanese        | Ishii         |\n",
      "| 24 | Japanese        | MiiPro        |\n",
      "| 25 | Japanese        | Miyata        |\n",
      "| 26 | Korean          | Ryu           |\n",
      "| 27 | Mandarin        | Tong          |\n",
      "| 28 | Norwegian       | Garmann       |\n",
      "| 29 | Persian         | Family        |\n",
      "| 30 | Polish          | WeistJarosz   |\n",
      "| 31 | Portuguese      | Santos        |\n",
      "| 32 | Spanish         | Nieva         |\n",
      "| 33 | Spanish         | Remedi        |\n",
      "| 34 | Swedish         | Andren        |\n",
      "| 35 | Swedish         | Lund          |\n"
     ]
    }
   ],
   "source": [
    "# how many corpora with language names\n",
    "\n",
    "corpora_langs = rand_dat_inc.groupby(['Language_name','corpus_name']).agg(['unique']).reset_index()\n",
    "corpora_langs = corpora_langs.iloc[:, 0:2]\n",
    "corpora_langs.columns.values[0] = \"Language_name\"\n",
    "corpora_langs.columns.values[1] = \"corpus_name\"\n",
    "\n",
    "print(corpora_langs.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_dat = rand_dat_inc[rand_dat_inc[\"speaker_role\"]==\"Target_Child\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_dat.to_csv(\"../data/child_dat.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "----\n",
    "#### Geographic distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "geo_dat = pd.read_csv(\"../data/langs_and_countries.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create language name column\n",
    "\n",
    "geo_dat=geo_dat.rename(columns={\"Language\":\"language\"})\n",
    "\n",
    "geo_dat=geo_dat.merge(language_labels,on='language',how=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R \n",
    "\n",
    "theme_black = function(base_size = 11, base_family = \"\") {\n",
    " \n",
    "  theme_grey(base_size = base_size, base_family = base_family) %+replace%\n",
    " \n",
    "    theme(\n",
    "      # Specify axis options\n",
    "      axis.line = element_line(colour = \"white\"),  \n",
    "      axis.text.x = element_text(color = \"white\",margin = margin(2, 2, 2, 2),size=8),  \n",
    "      axis.text.y = element_text(color = \"white\",hjust=1,margin = margin(2, 2, 2, 2)),  \n",
    "      axis.ticks = element_line(color = \"white\"),  \n",
    "      axis.title.x = element_text(size = base_size, color = \"white\"),  \n",
    "      axis.title.y = element_text(size = base_size, color = \"white\", angle = 90,margin = margin(0, 10, 0, 0)),  \n",
    "      # Specify legend options\n",
    "      legend.background = element_rect(color = NA, fill = \"black\"),  \n",
    "      legend.key = element_rect(color = \"white\",  fill = \"black\"),  \n",
    "      legend.key.size = unit(1.2, \"lines\"),  \n",
    "      legend.key.height = NULL,  \n",
    "      legend.key.width = NULL,      \n",
    "      legend.text = element_text(size = base_size*0.8, color = \"white\"),  \n",
    "      legend.title = element_text(size = base_size*0.8, face = \"bold\", hjust = 0, color = \"white\"),  \n",
    "      legend.position = \"right\",  \n",
    "      legend.text.align = NULL,  \n",
    "      legend.title.align = NULL,  \n",
    "      legend.direction = \"vertical\",  \n",
    "      legend.box = NULL, \n",
    "      # Specify panel options\n",
    "      panel.background = element_blank(),  \n",
    "      panel.border = element_blank(),  \n",
    "      panel.grid.major = element_blank(),  \n",
    "      panel.grid.minor = element_blank(),  \n",
    "#       panel.margin = unit(0.5, \"lines\"),   \n",
    "      # Specify facetting options\n",
    "      strip.background = element_rect(fill = \"black\", color = \"white\"),  \n",
    "      strip.text.x = element_text( color = \"white\"),  \n",
    "      strip.text.y = element_text(size = base_size*0.8, color = \"white\",angle = -90),  \n",
    "      # Specify plot options\n",
    "      plot.background = element_rect(color = \"black\", fill = \"black\"),  \n",
    "      plot.title = element_text(size = base_size, color = \"white\"),  \n",
    "      plot.margin = unit(rep(1, 4), \"lines\")\n",
    " \n",
    "    )\n",
    " \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%R -i geo_dat\n",
    "\n",
    "library(ggplot2)\n",
    "\n",
    "library(repr)\n",
    "options(repr.plot.width=11.7, repr.plot.height=6.2)\n",
    "\n",
    "mp <- NULL\n",
    "\n",
    "mapWorld <- borders(\"world\",\n",
    "                    colour = \"white\",\n",
    "#                     colour=\"gray50\", # with white background\n",
    "                    fill=\"gray75\") # create a layer of borders\n",
    "\n",
    "mp <- ggplot() + mapWorld\n",
    "\n",
    "mp <- mp +\n",
    "      geom_point(aes(x=geo_dat$longitude, y=geo_dat$latitude,color=geo_dat$Language_name), size=3) +\n",
    "      theme_black() +\n",
    "      theme_void() +\n",
    "      theme(text = element_text(size=16),\n",
    "            plot.background = element_rect(fill = \"black\"),\n",
    "            legend.title = element_blank(),\n",
    "            legend.position = c(0.92, 0.55),\n",
    "            legend.background = element_rect(fill=alpha(\"black\",0.90),\n",
    "                                             size=0, linetype=\"dotted\",\n",
    "                                             colour = \"black\"),\n",
    "            legend.text=element_text(size=16,colour=\"white\"))\n",
    "        \n",
    "# ggsave(\"../figures/geo_dat.pdf\", width = 11.7, height = 6.2,dpi = 1200)\n",
    "ggsave(\"../figures/geo_dat_black.pdf\", width = 11.7, height = 6.2,dpi = 1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "age_counts = rand_dat_inc.groupby(['language','transcript_id','target_child_age']).nunique()\n",
    "age_counts = age_counts.iloc[:, 0:2].reset_index()\n",
    "age_counts['target_child_age'].mean()\n",
    "\n",
    "age_counts=age_counts.merge(language_labels,on='language',how=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%R -i age_counts\n",
    "\n",
    "library('ggplot2')\n",
    "\n",
    "p <- ggplot(data=age_counts, aes(x = target_child_age, fill = Language_name)) +\n",
    "     geom_histogram(binwidth=2.5) +\n",
    "     facet_wrap(. ~ Language_name,ncol = 7) +\n",
    "     theme_classic() + theme(text = element_text(size=16),\n",
    "                             legend.title = element_blank(),\n",
    "                             legend.background = element_rect(fill=alpha(\"white\",0.90),\n",
    "                                                            size=0, linetype=\"dotted\",\n",
    "                                                            colour = \"white\"),\n",
    "                             legend.text=element_text(size=16)) +\n",
    "     labs(x = \"Child age (months)\", y = \"Freq\")\n",
    "    \n",
    "     ggsave(\"../figures/age_hist.pdf\", width = 11.7, height = 6.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_dat_inc_age = rand_dat_inc.groupby(['Language_name','transcript_id','target_child_id','target_child_age']).nunique().reset_index()\n",
    "rand_dat_inc_age = rand_dat_inc_age[['Language_name','transcript_id','target_child_id','target_child_age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m# A tibble: 14 × 7\u001b[39m\n",
      "   Language_name transcript_id_mean target_child_id_mean target_child_age_mean\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m                \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m                 \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m Croatian                  \u001b[4m2\u001b[24m\u001b[4m8\u001b[24m147.               \u001b[4m1\u001b[24m\u001b[4m7\u001b[24m516.                  23.7\n",
      "\u001b[90m 2\u001b[39m English                   \u001b[4m1\u001b[24m\u001b[4m5\u001b[24m216.                \u001b[4m7\u001b[24m738.                  17.1\n",
      "\u001b[90m 3\u001b[39m Estonian                  \u001b[4m1\u001b[24m\u001b[4m9\u001b[24m546.               \u001b[4m1\u001b[24m\u001b[4m2\u001b[24m373.                  23.7\n",
      "\u001b[90m 4\u001b[39m French                    \u001b[4m4\u001b[24m\u001b[4m3\u001b[24m330.               \u001b[4m2\u001b[24m\u001b[4m2\u001b[24m501.                  21.8\n",
      "\u001b[90m 5\u001b[39m German                    \u001b[4m2\u001b[24m\u001b[4m9\u001b[24m927.               \u001b[4m1\u001b[24m\u001b[4m8\u001b[24m351.                  25.8\n",
      "\u001b[90m 6\u001b[39m Japanese                  \u001b[4m2\u001b[24m\u001b[4m0\u001b[24m943.               \u001b[4m1\u001b[24m\u001b[4m3\u001b[24m487.                  21.9\n",
      "\u001b[90m 7\u001b[39m Korean                    \u001b[4m2\u001b[24m\u001b[4m7\u001b[24m233.               \u001b[4m1\u001b[24m\u001b[4m6\u001b[24m738                   21.4\n",
      "\u001b[90m 8\u001b[39m Mandarin                  \u001b[4m1\u001b[24m\u001b[4m6\u001b[24m284.                \u001b[4m9\u001b[24m827                   21.2\n",
      "\u001b[90m 9\u001b[39m Norwegian                 \u001b[4m4\u001b[24m\u001b[4m3\u001b[24m952.               \u001b[4m2\u001b[24m\u001b[4m2\u001b[24m855.                  18.4\n",
      "\u001b[90m10\u001b[39m Persian                   \u001b[4m2\u001b[24m\u001b[4m0\u001b[24m198.               \u001b[4m1\u001b[24m\u001b[4m3\u001b[24m148                   26.7\n",
      "\u001b[90m11\u001b[39m Polish                    \u001b[4m4\u001b[24m\u001b[4m7\u001b[24m739                \u001b[4m2\u001b[24m\u001b[4m4\u001b[24m114                   22.7\n",
      "\u001b[90m12\u001b[39m Portuguese                \u001b[4m2\u001b[24m\u001b[4m2\u001b[24m412.               \u001b[4m1\u001b[24m\u001b[4m4\u001b[24m292.                  23.8\n",
      "\u001b[90m13\u001b[39m Spanish                   \u001b[4m1\u001b[24m\u001b[4m1\u001b[24m896.                \u001b[4m5\u001b[24m856.                  23.6\n",
      "\u001b[90m14\u001b[39m Swedish                   \u001b[4m1\u001b[24m\u001b[4m1\u001b[24m082.                \u001b[4m5\u001b[24m619.                  22.8\n",
      "\u001b[90m# … with 3 more variables: transcript_id_std.error <dbl>,\u001b[39m\n",
      "\u001b[90m#   target_child_id_std.error <dbl>, target_child_age_std.error <dbl>\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "%%R -i rand_dat_inc_age\n",
    "\n",
    "library('plotrix')\n",
    "library('dplyr')\n",
    "\n",
    "age_summary <- rand_dat_inc_age %>% group_by(Language_name) %>%\n",
    "summarise_all(funs(mean,std.error))\n",
    "age_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "library('ggplot2')\n",
    "\n",
    "\n",
    "p <- ggplot(data=age_summary, aes(x = target_child_age_mean,\n",
    "                                  y=Language_name, moe = target_child_age_std.error,\n",
    "                                  color = Language_name)) +\n",
    "     geom_point(aes(x = target_child_age_mean), size = 3) +\n",
    "     geom_errorbarh(aes(xmin = target_child_age_mean - target_child_age_std.error,\n",
    "                        xmax = target_child_age_mean + target_child_age_std.error), height = 0.5, size = 2) +\n",
    "     theme_classic() + theme(text = element_text(size=16),\n",
    "                             legend.title = element_blank(),\n",
    "                             legend.background = element_rect(fill=alpha(\"white\",0.90),\n",
    "                                                            size=0, linetype=\"dotted\",\n",
    "                                                            colour = \"white\"),\n",
    "                             legend.text=element_text(size=16)) +\n",
    "     labs(x = \"Child age (months)\", y = \"Language\") +\n",
    "     scale_y_discrete(limits=rev)\n",
    "     ggsave(\"../figures/age_line.pdf\", width = 11.7, height = 6.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "#### Contingency assignment"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# create \"parent\" column\n",
    "#\n",
    "# add to this to include more speakers in \"caregiver\" category\n",
    "#\n",
    "\n",
    "conditions = [\n",
    "    (rand_dat_inc[\"speaker_role\"]==\"Mother\") | (rand_dat_inc[\"speaker_role\"]==\"Father\"),\n",
    "    (rand_dat_inc[\"speaker_role\"]==\"Target_Child\")]\n",
    "\n",
    "choices = ['caregiver', 'target_child']\n",
    "\n",
    "rand_dat_inc['caregiver'] = np.select(conditions, choices, default='other')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a contingency window of 3 to start:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-ba5d7533e5c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrand_dat_inc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontingent_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_contingency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrand_dat_inc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# .001 buffer time to ensure that caregiver utterances that begin at the same moment as infant vocalizations are not artificially counted as contingent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/projects/Natural-Statistics-Cross-linguistic/analysis/data_proc/contingent_extraction.py\u001b[0m in \u001b[0;36massign_contingency\u001b[0;34m(df, window, buffer)\u001b[0m\n\u001b[1;32m     77\u001b[0m                                            tran_frame[\"media_start\"] <= (voc_onset) + window )]\n\u001b[1;32m     78\u001b[0m             \u001b[0;31m# duplicate start times need removed from child vocalizations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mwithin_window\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'media_start'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m                 \u001b[0mwithin_window\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwithin_window\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwithin_window\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"caregiver\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"caregiver\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mcont_parent_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwithin_window\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwithin_window\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"caregiver\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"caregiver\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mduplicated\u001b[0;34m(self, subset, keep)\u001b[0m\n\u001b[1;32m   6208\u001b[0m             \u001b[0mxnull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6209\u001b[0m         )\n\u001b[0;32m-> 6210\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6211\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"duplicated\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    439\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                 \u001b[0mmanager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode.data_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmanager\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"block\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__func__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m_get_option\u001b[0;34m(pat, silent)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;31m# walk the nested dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m_get_root\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m     \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_global_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rand_dat_inc = contingent_extraction.assign_contingency(rand_dat_inc,3,.001) # .001 buffer time to ensure that caregiver utterances that begin at the same moment as infant vocalizations are not artificially counted as contingent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_dat_inc.to_csv(\"../data/rand_dat_inc_master.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of contingent and non-contingent words (tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_dat_inc = pd.read_csv(\"../data/rand_dat_inc_master.csv\",index_col=0,low_memory=False)\n",
    "rand_dat_inc=rand_dat_inc[rand_dat_inc[\"language\"]!=\"ara\"]\n",
    "rand_dat_inc=rand_dat_inc[(rand_dat_inc[\"target_child_age\"]>=5) & (rand_dat_inc[\"target_child_age\"]<=30)]\n",
    "\n",
    "rand_dat_inc_cg = rand_dat_inc[rand_dat_inc[\"caregiver\"]==\"caregiver\"]\n",
    "\n",
    "rand_dat_inc_cg[\"contingent\"] = np.where(rand_dat_inc_cg[\"contingent\"]==1, \"contingent\", \"non-contingent\")\n",
    "\n",
    "rand_dat_inc_cg = rand_dat_inc_cg[rand_dat_inc_cg[\"gloss\"].notna()]\n",
    "rand_dat_inc_cg = rand_dat_inc_cg[rand_dat_inc_cg[\"gloss\"]!=\"xxx\"]\n",
    "rand_dat_inc_cg = rand_dat_inc_cg[rand_dat_inc_cg[\"gloss\"]!=\"yyy\"]\n",
    "rand_dat_inc_cg = rand_dat_inc_cg[rand_dat_inc_cg[\"gloss\"]!=\"www\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many contingent and non-contingent total words per language\n",
    "\n",
    "contingent_noncontingent_counts = rand_dat_inc_cg.groupby(['language','contingent']).size().to_frame('count').reset_index()\n",
    "\n",
    "print(contingent_noncontingent_counts.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# average number of total contingent and non-contingent words per transcript across languages\n",
    "\n",
    "contingent_noncontingent_count_avgs = rand_dat_inc_cg.groupby(['language','contingent','transcript_id']).size().to_frame('count').reset_index()\n",
    "\n",
    "contingent_noncontingent_count_avgs =  contingent_noncontingent_count_avgs.rename({'count': 'counts'}, axis=1)\n",
    "\n",
    "contingent_noncontingent_count_avgs = (contingent_noncontingent_count_avgs.groupby([\"language\",\"contingent\"])\n",
    "                                       .counts\n",
    "                                       .agg([\"mean\"])\n",
    "                                       .reset_index())\n",
    "\n",
    "contingent_noncontingent_count_avgs =  contingent_noncontingent_count_avgs.rename({'mean': 'means'}, axis=1)\n",
    "\n",
    "print(contingent_noncontingent_count_avgs.to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context proportions across languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_dat = pd.read_csv(\"../data/context_data.csv\")\n",
    "context_dat=context_dat.rename(columns={\"Language\":\"Language_name\"})\n",
    "context_dat=context_dat.rename(columns={\"Corpus\":\"corpus_name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_dat_inc=rand_dat_inc.merge(context_dat,on='corpus_name',how=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_dat_inc[\"Location\"] = rand_dat_inc[\"Location\"].fillna(\"NaN\")\n",
    "rand_dat_inc[\"Activity\"] = rand_dat_inc[\"Activity\"].fillna(\"NaN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_dat_inc[\"context\"] = rand_dat_inc[\"Location\"] + rand_dat_inc[\"Activity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_dat_inc[\"context\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_dat_inc=rand_dat_inc.rename(columns={\"Language_name_x\":\"Language_name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many transcripts per corpora per different context\n",
    "\n",
    "context_counts = rand_dat_inc.groupby(['Language_name','context','transcript_id']).nunique().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_table = context_counts.groupby(['Language_name','context']).size().to_frame('count').reset_index()\n",
    "\n",
    "print(count_table.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_table.to_csv(\"../data/context_counts_subject_level.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
